"""
æ™ºèƒ½åŒ¹é…å¼•æ“ - ComfyModelCleaner V2.0

å¤šçº§åŒ¹é…ç­–ç•¥ï¼šç²¾ç¡®åŒ¹é…ã€éƒ¨åˆ†åŒ¹é…ã€æ¨¡ç³ŠåŒ¹é…ã€è·¯å¾„åŒ¹é…ã€‚
"""

import re
import difflib
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass

from .model_discovery import ModelInfo
from .reference_extractor import ModelReference


@dataclass
class MatchResult:
    """åŒ¹é…ç»“æœ"""
    model_info: ModelInfo
    references: List[ModelReference]
    match_type: str  # 'exact', 'partial', 'fuzzy', 'path'
    confidence: float  # 0.0 - 1.0
    match_details: Dict[str, Any]


class IntelligentMatcher:
    """æ™ºèƒ½åŒ¹é…å¼•æ“"""

    def __init__(self):
        self.match_cache = {}
        self._node_name_cache = {}  # ç¼“å­˜æ–‡ä»¶è·¯å¾„åˆ°èŠ‚ç‚¹åç§°çš„æ˜ å°„
        self._ui_extensions = {  # UIç›¸å…³æ‰©å±•ï¼Œä¸å®é™…ä½¿ç”¨æ¨¡å‹
            'manager', 'comfyui-manager', 'comfyui_manager',
            'frontend', 'ui', 'interface', 'web', 'browser',
            'workspace', 'settings', 'config', 'utils', 'helper'
        }

    def match_models(self, discovered_models: Dict[str, List[ModelInfo]],
                    extracted_references: Dict[str, List[ModelReference]]) -> Dict[str, MatchResult]:
        """
        å¤šçº§åŒ¹é…ç­–ç•¥:
        1. ç²¾ç¡®åŒ¹é… (confidence: 90-100%)
        2. éƒ¨åˆ†åŒ¹é… (confidence: 70-90%)
        3. æ¨¡ç³ŠåŒ¹é… (confidence: 40-60%)
        4. è·¯å¾„åŒ¹é… (confidence: 50-70%)

        Args:
            discovered_models: å‘ç°çš„æ¨¡å‹
            extracted_references: æå–çš„å¼•ç”¨

        Returns:
            Dict[str, MatchResult]: åŒ¹é…ç»“æœï¼Œé”®ä¸ºæ¨¡å‹æ ‡è¯†ç¬¦
        """
        print("ğŸ¯ å¼€å§‹æ™ºèƒ½åŒ¹é…...")

        # åˆå¹¶æ‰€æœ‰æ¨¡å‹
        all_models = []
        for model_list in discovered_models.values():
            all_models.extend(model_list)

        # åˆå¹¶æ‰€æœ‰å¼•ç”¨å¹¶é¢„å»ºç«‹èŠ‚ç‚¹åç§°ç¼“å­˜
        all_references = []
        for ref_list in extracted_references.values():
            all_references.extend(ref_list)

        # é¢„å»ºç«‹èŠ‚ç‚¹åç§°ç¼“å­˜ï¼Œä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰å¼•ç”¨
        self._build_node_name_cache(all_references)

        print(f"  æ¨¡å‹æ€»æ•°: {len(all_models)}")
        print(f"  å¼•ç”¨æ€»æ•°: {len(all_references)}")

        match_results = {}

        for model in all_models:
            model_id = f"{model.directory}/{model.name}"

            # å°è¯•å„ç§åŒ¹é…ç­–ç•¥
            best_match = self._find_best_match(model, all_references)

            if best_match:
                match_results[model_id] = best_match
                # è½¬æ¢ä¸ºæœªä½¿ç”¨ç½®ä¿¡åº¦æ˜¾ç¤º (100 - ä½¿ç”¨ç½®ä¿¡åº¦)
                unused_confidence = 100 - (best_match.confidence * 100)

                # æå–èŠ‚ç‚¹åç§°ä¿¡æ¯ï¼ˆä½¿ç”¨ç¼“å­˜ä¼˜åŒ–ï¼‰
                node_names = self._get_filtered_node_names(best_match.references)
                if node_names:
                    node_info = f"å¯èƒ½è¢« {', '.join(node_names)} èŠ‚ç‚¹ä½¿ç”¨"
                else:
                    match_type_display = {
                        'exact': 'ç²¾ç¡®åŒ¹é…',
                        'partial': 'éƒ¨åˆ†åŒ¹é…',
                        'fuzzy': 'æ¨¡ç³ŠåŒ¹é…',
                        'path': 'è·¯å¾„åŒ¹é…'
                    }
                    node_info = f"{match_type_display.get(best_match.match_type, best_match.match_type)}!"

                # æ ¼å¼åŒ–å¯¹é½è¾“å‡º
                model_name_width = 35  # æ¨¡å‹åç§°åˆ—å®½åº¦
                node_info_width = 45   # èŠ‚ç‚¹ä¿¡æ¯åˆ—å®½åº¦

                # æˆªæ–­è¿‡é•¿çš„æ¨¡å‹åç§°
                display_name = model.name[:model_name_width-3] + "..." if len(model.name) > model_name_width else model.name
                # æˆªæ–­è¿‡é•¿çš„èŠ‚ç‚¹ä¿¡æ¯
                display_node_info = node_info[:node_info_width-3] + "..." if len(node_info) > node_info_width else node_info

                print(f"  âœ… {display_name:<{model_name_width}} {display_node_info:<{node_info_width}} (æœªä½¿ç”¨ç½®ä¿¡åº¦: {unused_confidence:3.0f}%)")
            else:
                # åˆ›å»ºæ— åŒ¹é…ç»“æœ
                match_results[model_id] = MatchResult(
                    model_info=model,
                    references=[],
                    match_type='none',
                    confidence=0.0,
                    match_details={'reason': 'no_references_found'}
                )

        matched_count = sum(1 for result in match_results.values() if result.confidence > 0)
        print(f"âœ… åŒ¹é…å®Œæˆ: {matched_count}/{len(all_models)} ä¸ªæ¨¡å‹æœ‰å¼•ç”¨")

        return match_results

    def _find_best_match(self, model: ModelInfo, references: List[ModelReference]) -> Optional[MatchResult]:
        """
        ä¸ºå•ä¸ªæ¨¡å‹æ‰¾åˆ°æœ€ä½³åŒ¹é…

        Args:
            model: æ¨¡å‹ä¿¡æ¯
            references: æ‰€æœ‰å¼•ç”¨

        Returns:
            Optional[MatchResult]: æœ€ä½³åŒ¹é…ç»“æœ
        """
        # å°è¯•ä¸åŒçš„åŒ¹é…ç­–ç•¥
        strategies = [
            ('exact', self.exact_match),
            ('partial', self.partial_match),
            ('fuzzy', self.fuzzy_match),
            ('path', self.path_match)
        ]

        best_result = None
        best_confidence = 0.0

        for _, strategy_func in strategies:
            result = strategy_func(model, references)
            if result and result.confidence > best_confidence:
                best_result = result
                best_confidence = result.confidence

        return best_result

    def exact_match(self, model: ModelInfo, references: List[ModelReference]) -> Optional[MatchResult]:
        """
        ç²¾ç¡®åŒ¹é…

        Args:
            model: æ¨¡å‹ä¿¡æ¯
            references: å¼•ç”¨åˆ—è¡¨

        Returns:
            Optional[MatchResult]: åŒ¹é…ç»“æœ
        """
        matched_refs = []

        for ref in references:
            # å®Œå…¨åŒ¹é…æ¨¡å‹åç§°
            if model.name.lower() == ref.model_name.lower():
                matched_refs.append(ref)
            # åŒ¹é…å¸¦æ‰©å±•åçš„æ–‡ä»¶å
            elif model.model_type == 'file':
                full_name = f"{model.name}{model.extension}"
                if full_name.lower() == ref.model_name.lower():
                    matched_refs.append(ref)

        if matched_refs:
            confidence = 0.95 + (len(matched_refs) * 0.01)  # å¤šä¸ªå¼•ç”¨å¢åŠ ç½®ä¿¡åº¦
            confidence = min(1.0, confidence)

            return MatchResult(
                model_info=model,
                references=matched_refs,
                match_type='exact',
                confidence=confidence,
                match_details={
                    'matched_names': [ref.model_name for ref in matched_refs],
                    'reference_count': len(matched_refs)
                }
            )

        return None

    def partial_match(self, model: ModelInfo, references: List[ModelReference]) -> Optional[MatchResult]:
        """
        éƒ¨åˆ†åŒ¹é… (å»é™¤ç‰ˆæœ¬å·ã€å‰ç¼€ç­‰)

        Args:
            model: æ¨¡å‹ä¿¡æ¯
            references: å¼•ç”¨åˆ—è¡¨

        Returns:
            Optional[MatchResult]: åŒ¹é…ç»“æœ
        """
        matched_refs = []
        model_clean = self._clean_name_for_matching(model.name)

        for ref in references:
            ref_clean = self._clean_name_for_matching(ref.model_name)

            # éƒ¨åˆ†åŒ¹é…ç­–ç•¥
            if self._is_partial_match(model_clean, ref_clean):
                matched_refs.append(ref)

        if matched_refs:
            # éƒ¨åˆ†åŒ¹é…çš„ç½®ä¿¡åº¦è¾ƒä½
            base_confidence = 0.75
            confidence = base_confidence + (len(matched_refs) * 0.02)
            confidence = min(0.90, confidence)

            return MatchResult(
                model_info=model,
                references=matched_refs,
                match_type='partial',
                confidence=confidence,
                match_details={
                    'cleaned_model_name': model_clean,
                    'matched_references': [(ref.model_name, self._clean_name_for_matching(ref.model_name))
                                         for ref in matched_refs],
                    'reference_count': len(matched_refs)
                }
            )

        return None

    def fuzzy_match(self, model: ModelInfo, references: List[ModelReference]) -> Optional[MatchResult]:
        """
        æ¨¡ç³ŠåŒ¹é… (ç¼–è¾‘è·ç¦»ã€å…³é”®è¯åŒ¹é…)

        Args:
            model: æ¨¡å‹ä¿¡æ¯
            references: å¼•ç”¨åˆ—è¡¨

        Returns:
            Optional[MatchResult]: åŒ¹é…ç»“æœ
        """
        matched_refs = []
        model_name = model.name.lower()

        for ref in references:
            ref_name = ref.model_name.lower()

            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = difflib.SequenceMatcher(None, model_name, ref_name).ratio()

            # å…³é”®è¯åŒ¹é…
            keyword_match = self._keyword_similarity(model_name, ref_name)

            # ç»¼åˆç›¸ä¼¼åº¦
            combined_similarity = max(similarity, keyword_match)

            # å¯¹äºç‰¹å®šæ¨¡å‹ç±»å‹é™ä½é˜ˆå€¼
            threshold = 0.6
            if any(keyword in model_name for keyword in ['segformer', 'clip', 'vit', 'sam']):
                threshold = 0.4  # é™ä½é˜ˆå€¼ä»¥æé«˜åŒ¹é…ç‡

            if combined_similarity > threshold:
                matched_refs.append((ref, combined_similarity))

        if matched_refs:
            # æŒ‰ç›¸ä¼¼åº¦æ’åº
            matched_refs.sort(key=lambda x: x[1], reverse=True)

            # è®¡ç®—ç½®ä¿¡åº¦
            best_similarity = matched_refs[0][1]
            confidence = 0.4 + (best_similarity * 0.3)  # 40-70%

            return MatchResult(
                model_info=model,
                references=[ref for ref, _ in matched_refs],
                match_type='fuzzy',
                confidence=confidence,
                match_details={
                    'similarities': [(ref.model_name, sim) for ref, sim in matched_refs],
                    'best_similarity': best_similarity,
                    'reference_count': len(matched_refs)
                }
            )

        return None

    def path_match(self, model: ModelInfo, references: List[ModelReference]) -> Optional[MatchResult]:
        """
        è·¯å¾„åŒ¹é… (åŸºäºç›®å½•ç»“æ„)

        Args:
            model: æ¨¡å‹ä¿¡æ¯
            references: å¼•ç”¨åˆ—è¡¨

        Returns:
            Optional[MatchResult]: åŒ¹é…ç»“æœ
        """
        matched_refs = []

        for ref in references:
            # æ£€æŸ¥å¼•ç”¨æ˜¯å¦åŒ…å«æ¨¡å‹çš„ç›®å½•ä¿¡æ¯
            if self._is_path_match(model, ref):
                matched_refs.append(ref)

        if matched_refs:
            confidence = 0.5 + (len(matched_refs) * 0.05)
            confidence = min(0.75, confidence)

            return MatchResult(
                model_info=model,
                references=matched_refs,
                match_type='path',
                confidence=confidence,
                match_details={
                    'model_directory': model.directory,
                    'model_path': model.relative_path,
                    'matched_paths': [ref.context for ref in matched_refs],
                    'reference_count': len(matched_refs)
                }
            )

        return None

    def _clean_name_for_matching(self, name: str) -> str:
        """
        æ¸…ç†åç§°ç”¨äºåŒ¹é…

        Args:
            name: åŸå§‹åç§°

        Returns:
            str: æ¸…ç†åçš„åç§°
        """
        # ç§»é™¤å¸¸è§çš„ç‰ˆæœ¬å·å’Œå‰ç¼€
        clean = name.lower()

        # ç§»é™¤ç‰ˆæœ¬å·æ¨¡å¼
        version_patterns = [
            r'[-_]v?\d+(\.\d+)*',  # -v1.0, _v2.1, -1.5
            r'[-_]\d+[a-z]?$',     # -1a, _2b
            r'[-_](alpha|beta|rc)\d*',  # -alpha, -beta1, -rc2
        ]

        for pattern in version_patterns:
            clean = re.sub(pattern, '', clean)

        # ç§»é™¤å¸¸è§å‰ç¼€å’Œåç¼€
        prefixes_suffixes = [
            'comfyui_', 'comfyui-', 'sd_', 'sd-', 'xl_', 'xl-',
            '_model', '-model', '_checkpoint', '-checkpoint'
        ]

        for fix in prefixes_suffixes:
            if clean.startswith(fix):
                clean = clean[len(fix):]
            if clean.endswith(fix):
                clean = clean[:-len(fix)]

        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œåªä¿ç•™å­—æ¯æ•°å­—
        clean = re.sub(r'[^a-z0-9]', '', clean)

        return clean.strip()

    def _is_partial_match(self, name1: str, name2: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦æ˜¯éƒ¨åˆ†åŒ¹é…

        Args:
            name1: åç§°1
            name2: åç§°2

        Returns:
            bool: æ˜¯å¦åŒ¹é…
        """
        if not name1 or not name2:
            return False

        # é•¿åº¦å·®å¼‚å¤ªå¤§åˆ™ä¸åŒ¹é…
        if abs(len(name1) - len(name2)) > max(len(name1), len(name2)) * 0.5:
            return False

        # æ£€æŸ¥åŒ…å«å…³ç³»
        if name1 in name2 or name2 in name1:
            return True

        # æ£€æŸ¥å…¬å…±å­ä¸²
        common_length = len(self._longest_common_substring(name1, name2))
        min_length = min(len(name1), len(name2))

        return common_length >= min_length * 0.7

    def _longest_common_substring(self, s1: str, s2: str) -> str:
        """
        æ‰¾åˆ°æœ€é•¿å…¬å…±å­ä¸²

        Args:
            s1: å­—ç¬¦ä¸²1
            s2: å­—ç¬¦ä¸²2

        Returns:
            str: æœ€é•¿å…¬å…±å­ä¸²
        """
        m, n = len(s1), len(s2)
        dp = [[0] * (n + 1) for _ in range(m + 1)]

        max_length = 0
        ending_pos = 0

        for i in range(1, m + 1):
            for j in range(1, n + 1):
                if s1[i-1] == s2[j-1]:
                    dp[i][j] = dp[i-1][j-1] + 1
                    if dp[i][j] > max_length:
                        max_length = dp[i][j]
                        ending_pos = i
                else:
                    dp[i][j] = 0

        return s1[ending_pos - max_length:ending_pos]

    def _keyword_similarity(self, name1: str, name2: str) -> float:
        """
        åŸºäºå…³é”®è¯çš„ç›¸ä¼¼åº¦è®¡ç®—

        Args:
            name1: åç§°1
            name2: åç§°2

        Returns:
            float: ç›¸ä¼¼åº¦ (0.0 - 1.0)
        """
        # æå–å…³é”®è¯
        keywords1 = set(re.findall(r'[a-z]+', name1.lower()))
        keywords2 = set(re.findall(r'[a-z]+', name2.lower()))

        if not keywords1 or not keywords2:
            return 0.0

        # è®¡ç®—äº¤é›†å’Œå¹¶é›†
        intersection = keywords1 & keywords2
        union = keywords1 | keywords2

        # åŸºç¡€Jaccardç›¸ä¼¼åº¦
        jaccard_similarity = len(intersection) / len(union) if union else 0.0

        # å¢å¼ºåŒ¹é…ï¼šæ£€æŸ¥é‡è¦å…³é”®è¯
        important_keywords = {'segformer', 'clip', 'vit', 'sam', 'controlnet', 'lora', 'vae'}

        # å¦‚æœæœ‰é‡è¦å…³é”®è¯åŒ¹é…ï¼Œç»™äºˆé¢å¤–åŠ åˆ†
        important_matches = intersection & important_keywords
        if important_matches:
            # é‡è¦å…³é”®è¯åŒ¹é…æ—¶ï¼Œæé«˜ç›¸ä¼¼åº¦
            bonus = len(important_matches) * 0.3
            jaccard_similarity = min(1.0, jaccard_similarity + bonus)

        # æ£€æŸ¥ä¸»è¦æ¨¡å‹ç±»å‹åŒ¹é…ï¼ˆå¦‚segformerï¼‰
        for keyword in important_keywords:
            if keyword in name1.lower() and keyword in name2.lower():
                # å¦‚æœä¸¤ä¸ªåç§°éƒ½åŒ…å«ç›¸åŒçš„é‡è¦å…³é”®è¯ï¼Œè‡³å°‘ç»™0.5çš„ç›¸ä¼¼åº¦
                jaccard_similarity = max(jaccard_similarity, 0.5)
                break

        return jaccard_similarity

    def _is_path_match(self, model: ModelInfo, reference: ModelReference) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦æ˜¯è·¯å¾„åŒ¹é…

        Args:
            model: æ¨¡å‹ä¿¡æ¯
            reference: å¼•ç”¨ä¿¡æ¯

        Returns:
            bool: æ˜¯å¦åŒ¹é…
        """
        # æ£€æŸ¥å¼•ç”¨ä¸Šä¸‹æ–‡æ˜¯å¦åŒ…å«æ¨¡å‹ç›®å½•
        context_lower = reference.context.lower()

        # æ£€æŸ¥ç›®å½•ååŒ¹é…
        if model.directory.lower() in context_lower:
            return True

        # æ£€æŸ¥ç›¸å¯¹è·¯å¾„åŒ¹é…
        path_parts = Path(model.relative_path).parts
        for part in path_parts:
            if part.lower() in context_lower:
                return True

        # æ£€æŸ¥æºæ–‡ä»¶è·¯å¾„æ˜¯å¦ä¸æ¨¡å‹ç›¸å…³
        if reference.source_file:
            source_path = Path(reference.source_file)
            # å¦‚æœå¼•ç”¨æ¥è‡ªä¸æ¨¡å‹ç›®å½•ç›¸å…³çš„èŠ‚ç‚¹
            if model.directory.lower() in str(source_path).lower():
                return True

        return False

    def _build_node_name_cache(self, references: List[ModelReference]):
        """
        é¢„å»ºç«‹èŠ‚ç‚¹åç§°ç¼“å­˜ï¼Œä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰å¼•ç”¨ä»¥æé«˜æ€§èƒ½

        Args:
            references: æ‰€æœ‰æ¨¡å‹å¼•ç”¨åˆ—è¡¨
        """
        print("  ğŸ”§ å»ºç«‹èŠ‚ç‚¹åç§°ç¼“å­˜...")

        for ref in references:
            if ref.source_file and ref.source_file not in self._node_name_cache:
                node_name = self._extract_node_name_from_path(ref.source_file)
                self._node_name_cache[ref.source_file] = node_name

        print(f"  âœ… ç¼“å­˜å»ºç«‹å®Œæˆï¼Œå…± {len(self._node_name_cache)} ä¸ªæ–‡ä»¶è·¯å¾„")

    def _extract_node_name_from_path(self, file_path: str) -> Optional[str]:
        """
        ä»æ–‡ä»¶è·¯å¾„ä¸­æå–èŠ‚ç‚¹åç§°

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            Optional[str]: èŠ‚ç‚¹åç§°ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
        """
        try:
            source_path = Path(file_path)
            parts = source_path.parts

            # æ‰¾åˆ°custom_nodesåœ¨è·¯å¾„ä¸­çš„ä½ç½®
            custom_nodes_index = -1
            for i, part in enumerate(parts):
                if part.lower() == 'custom_nodes':
                    custom_nodes_index = i
                    break

            # å¦‚æœæ‰¾åˆ°custom_nodesï¼Œä¸‹ä¸€ä¸ªéƒ¨åˆ†å°±æ˜¯èŠ‚ç‚¹åç§°
            if custom_nodes_index >= 0 and custom_nodes_index + 1 < len(parts):
                node_name = parts[custom_nodes_index + 1]

                # æ¸…ç†èŠ‚ç‚¹åç§°ï¼Œç§»é™¤å¸¸è§çš„å‰ç¼€
                if node_name.startswith('ComfyUI-'):
                    node_name = node_name[8:]  # ç§»é™¤ 'ComfyUI-' å‰ç¼€
                elif node_name.startswith('comfyui-'):
                    node_name = node_name[8:]  # ç§»é™¤ 'comfyui-' å‰ç¼€

                return node_name

        except (IndexError, AttributeError):
            pass

        return None

    def _get_filtered_node_names(self, references: List[ModelReference]) -> List[str]:
        """
        è·å–è¿‡æ»¤åçš„èŠ‚ç‚¹åç§°åˆ—è¡¨

        Args:
            references: æ¨¡å‹å¼•ç”¨åˆ—è¡¨

        Returns:
            List[str]: è¿‡æ»¤åçš„èŠ‚ç‚¹åç§°åˆ—è¡¨
        """
        node_names = set()

        for ref in references:
            if ref.source_file:
                # ä»ç¼“å­˜ä¸­è·å–èŠ‚ç‚¹åç§°
                node_name = self._node_name_cache.get(ref.source_file)
                if node_name:
                    # è¿‡æ»¤æ‰UIç›¸å…³æ‰©å±•
                    node_name_lower = node_name.lower()
                    if not any(ui_ext in node_name_lower for ui_ext in self._ui_extensions):
                        node_names.add(node_name)

        # è¿”å›æ’åºåçš„åˆ—è¡¨ï¼Œæœ€å¤šæ˜¾ç¤º3ä¸ªèŠ‚ç‚¹
        return sorted(list(node_names))[:3]


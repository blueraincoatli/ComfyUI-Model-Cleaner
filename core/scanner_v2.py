"""
æ–°ç‰ˆæ‰«æå™¨ - ComfyModelCleaner V2.0

é›†æˆæ‰€æœ‰æ¨¡å—çš„ä¸»æ‰«ææµç¨‹ï¼Œæä¾›é«˜ç²¾åº¦çš„æ¨¡å‹ä½¿ç”¨åˆ†æã€‚
"""

import time
from pathlib import Path
from typing import Dict, List, Set, Optional, Any
from dataclasses import dataclass

from .model_discovery import ModelDiscovery, ModelInfo
from .reference_extractor import ReferenceExtractor, ModelReference
from .matcher import IntelligentMatcher, MatchResult
from .confidence_calculator import ConfidenceCalculator, ConfidenceFactors
from .github_analyzer import GitHubAnalyzer, GitHubRepoInfo
from .utils import get_custom_nodes_dir, format_file_size


@dataclass
class ScanResultV2:
    """V2æ‰«æç»“æœ"""
    # åŸºç¡€ç»Ÿè®¡
    total_models: int
    single_file_models: int
    directory_models: int

    # ä½¿ç”¨åˆ†æ
    used_models: List[ModelInfo]
    unused_models: List[ModelInfo]
    uncertain_models: List[ModelInfo]

    # è¯¦ç»†åˆ†æ
    match_results: Dict[str, MatchResult]
    confidence_analysis: Dict[str, ConfidenceFactors]
    github_analysis: Optional[Dict[str, GitHubRepoInfo]]

    # ç»Ÿè®¡ä¿¡æ¯
    total_size_bytes: int
    used_size_bytes: int
    unused_size_bytes: int
    potential_savings_bytes: int

    # å…ƒæ•°æ®
    scan_time: str
    scan_timestamp: float
    scan_config: Dict[str, Any]


class ScanCancelledException(Exception):
    """æ‰«æè¢«å–æ¶ˆå¼‚å¸¸"""
    pass


class ProgressReporter:
    """è¿›åº¦æŠ¥å‘Šå™¨"""

    def __init__(self):
        self.current_step = 0
        self.total_steps = 5
        self.cancelled = False

    def check_cancellation(self):
        """æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ"""
        if self.cancelled:
            raise ScanCancelledException("æ‰«æè¢«ç”¨æˆ·å–æ¶ˆ")

    def cancel(self):
        """å–æ¶ˆæ‰«æ"""
        self.cancelled = True
        print("âš ï¸ æ‰«æè¢«å–æ¶ˆ")

    def report_discovery_progress(self, current: int, total: int):
        """æŠ¥å‘Šæ¨¡å‹å‘ç°è¿›åº¦"""
        self.check_cancellation()
        print(f"  [1/5] æ¨¡å‹å‘ç°: {current}/{total}")

    def report_extraction_progress(self, node_name: str, current: int, total: int):
        """æŠ¥å‘Šå¼•ç”¨æå–è¿›åº¦"""
        self.check_cancellation()
        print(f"  [2/5] å¼•ç”¨æå–: {node_name} ({current}/{total})")

    def report_matching_progress(self, current: int, total: int):
        """æŠ¥å‘ŠåŒ¹é…è¿›åº¦"""
        self.check_cancellation()
        print(f"  [3/5] æ™ºèƒ½åŒ¹é…: {current}/{total}")

    def report_confidence_progress(self, current: int, total: int):
        """æŠ¥å‘Šç½®ä¿¡åº¦è®¡ç®—è¿›åº¦"""
        self.check_cancellation()
        print(f"  [4/5] ç½®ä¿¡åº¦è®¡ç®—: {current}/{total}")

    def report_github_progress(self, current: int, total: int):
        """æŠ¥å‘ŠGitHubåˆ†æè¿›åº¦"""
        self.check_cancellation()
        print(f"  [5/5] GitHubåˆ†æ: {current}/{total}")


class ModelScannerV2:
    """æ–°ç‰ˆæ¨¡å‹æ‰«æå™¨"""

    def __init__(self):
        self.discovery = ModelDiscovery()
        self.extractor = ReferenceExtractor()
        self.matcher = IntelligentMatcher()
        self.calculator = ConfidenceCalculator()
        self.github = None  # å°†åœ¨scan_unused_modelsä¸­æ ¹æ®é…ç½®åˆå§‹åŒ–
        self.reporter = ProgressReporter()

    def scan_unused_models(self, config: Dict[str, Any]) -> ScanResultV2:
        """
        ä¸»æ‰«ææµç¨‹:
        1. å‘ç°æ‰€æœ‰æ¨¡å‹
        2. æå–æ‰€æœ‰å¼•ç”¨
        3. GitHubå¢å¼ºåˆ†æï¼ˆå¯é€‰ï¼Œåœ¨æ™ºèƒ½åŒ¹é…å‰è¿›è¡Œï¼‰
        4. æ™ºèƒ½åŒ¹é…
        5. è®¡ç®—ç½®ä¿¡åº¦
        6. ç”ŸæˆæŠ¥å‘Š

        Args:
            config: æ‰«æé…ç½®

        Returns:
            ScanResultV2: æ‰«æç»“æœ
        """
        start_time = time.time()
        try:
            print("ğŸš€ å¼€å§‹ComfyModelCleaner V2.0 æ‰«æ...")

            # æ ¹æ®é…ç½®åˆå§‹åŒ–GitHubåˆ†æå™¨
            clear_cache = config.get('clear_cache', False)
            if config.get('github_analysis', False):
                # å¦‚æœéœ€è¦æ¸…é™¤ç¼“å­˜ï¼Œåˆ™ç¦ç”¨GitHubåˆ†æå™¨çš„ç¼“å­˜
                enable_github_cache = not clear_cache
                self.github = GitHubAnalyzer(enable_cache=enable_github_cache)
                if clear_cache:
                    print("ğŸ§¹ GitHubåˆ†æå™¨ç¼“å­˜å·²ç¦ç”¨")

            # 1. å‘ç°æ‰€æœ‰æ¨¡å‹
            print("\nğŸ“ é˜¶æ®µ1: æ¨¡å‹å‘ç°")
            self.reporter.check_cancellation()
            discovered_models = self.discovery.discover_models(config)
            self.reporter.check_cancellation()  # å‘ç°å®Œæˆåå†æ¬¡æ£€æŸ¥

            all_models = []
            all_models.extend(discovered_models['single_file_models'])
            all_models.extend(discovered_models['directory_models'])

            print(f"âœ… å‘ç° {len(all_models)} ä¸ªæ¨¡å‹")

            # 2. æå–æ‰€æœ‰å¼•ç”¨
            print("\nğŸ” é˜¶æ®µ2: å¼•ç”¨æå–")
            self.reporter.check_cancellation()
            node_dirs = self._get_active_node_directories()
            self.reporter.check_cancellation()
            extracted_references = self.extractor.extract_all_references(node_dirs)
            self.reporter.check_cancellation()  # æå–å®Œæˆåå†æ¬¡æ£€æŸ¥

            total_references = sum(len(refs) for refs in extracted_references.values())
            print(f"âœ… æå– {total_references} ä¸ªå¼•ç”¨")

            # 3. GitHubå¢å¼ºåˆ†æï¼ˆå¯é€‰ï¼Œåœ¨æ™ºèƒ½åŒ¹é…å‰è¿›è¡Œï¼‰
            github_analysis = None
            if config.get('github_analysis', False) and self.github is not None:
                print("\nğŸŒ é˜¶æ®µ3: GitHubå¢å¼ºåˆ†æ")
                self.reporter.check_cancellation()
                github_analysis = self.github.analyze_node_repositories(node_dirs)
                self.reporter.check_cancellation()  # GitHubåˆ†æå®Œæˆåå†æ¬¡æ£€æŸ¥
                print(f"âœ… åˆ†æ {len(github_analysis)} ä¸ªGitHubä»“åº“")
            else:
                print("\nâ­ï¸  è·³è¿‡GitHubåˆ†æ")

            # 4. æ™ºèƒ½åŒ¹é…ï¼ˆç»“åˆGitHubåˆ†æç»“æœï¼‰
            print("\nğŸ¯ é˜¶æ®µ4: æ™ºèƒ½åŒ¹é…")
            self.reporter.check_cancellation()
            match_results = self.matcher.match_models(discovered_models, extracted_references)
            self.reporter.check_cancellation()  # åŒ¹é…å®Œæˆåå†æ¬¡æ£€æŸ¥

            matched_count = sum(1 for result in match_results.values() if result.confidence > 0)
            print(f"âœ… åŒ¹é… {matched_count}/{len(all_models)} ä¸ªæ¨¡å‹")

            # 5. è®¡ç®—ç½®ä¿¡åº¦ï¼ˆç»“åˆGitHubåˆ†æç»“æœï¼‰
            print("\nğŸ“Š é˜¶æ®µ5: ç½®ä¿¡åº¦è®¡ç®—")
            self.reporter.check_cancellation()
            confidence_analysis = {}

            total_models = len(match_results)
            for i, (model_id, match_result) in enumerate(match_results.items()):
                self.reporter.check_cancellation()  # æ¯ä¸ªæ¨¡å‹éƒ½æ£€æŸ¥å–æ¶ˆ
                confidence_factors = self.calculator.calculate_usage_confidence(
                    match_result.model_info, match_result, github_analysis
                )
                confidence_analysis[model_id] = confidence_factors

                # æ¯10ä¸ªæ¨¡å‹æŠ¥å‘Šä¸€æ¬¡è¿›åº¦
                if (i + 1) % 10 == 0 or (i + 1) == total_models:
                    print(f"  ç½®ä¿¡åº¦è®¡ç®—è¿›åº¦: {i + 1}/{total_models}")

            print(f"âœ… å®Œæˆ {len(confidence_analysis)} ä¸ªæ¨¡å‹çš„ç½®ä¿¡åº¦åˆ†æ")

            # 6. ç”Ÿæˆç»“æœ
            print("\nğŸ“‹ ç”Ÿæˆæ‰«æç»“æœ...")
            self.reporter.check_cancellation()
            scan_result = self._generate_scan_result(
                discovered_models, match_results, confidence_analysis,
                github_analysis, config, start_time
            )

            scan_time = time.time() - start_time
            print(f"\nâœ… æ‰«æå®Œæˆï¼è€—æ—¶ {scan_time:.2f} ç§’")
            print(f"ğŸ“Š ç»“æœæ‘˜è¦:")
            print(f"  - æ€»æ¨¡å‹: {scan_result.total_models}")
            print(f"  - æ­£åœ¨ä½¿ç”¨: {len(scan_result.used_models)}")
            print(f"  - å¯èƒ½æœªä½¿ç”¨: {len(scan_result.unused_models)}")
            print(f"  - ä¸ç¡®å®š: {len(scan_result.uncertain_models)}")
            print(f"  - æ½œåœ¨èŠ‚çœ: {format_file_size(scan_result.potential_savings_bytes)}")

            return scan_result

        except ScanCancelledException as e:
            print(f"âŒ {str(e)}")
            # è¿”å›ç©ºçš„æ‰«æç»“æœ
            scan_time = time.time() - start_time
            return self._create_empty_scan_result(config, scan_time)
        except Exception as e:
            print(f"âŒ æ‰«æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            # æ£€æŸ¥æ˜¯å¦æ˜¯å–æ¶ˆå¯¼è‡´çš„é”™è¯¯
            if self.reporter.cancelled:
                print("âŒ æ‰«æè¢«å–æ¶ˆ")
                scan_time = time.time() - start_time
                return self._create_empty_scan_result(config, scan_time)
            else:
                raise

    def _get_active_node_directories(self) -> List[Path]:
        """è·å–æ¿€æ´»çš„èŠ‚ç‚¹ç›®å½•"""
        custom_nodes_dir = get_custom_nodes_dir()
        active_dirs = []

        if custom_nodes_dir.exists():
            for node_dir in custom_nodes_dir.iterdir():
                if (node_dir.is_dir() and
                    not node_dir.name.startswith('.') and
                    self._is_active_node_directory(node_dir)):
                    active_dirs.append(node_dir)

        return active_dirs

    def _is_active_node_directory(self, node_dir: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯æ¿€æ´»çš„èŠ‚ç‚¹ç›®å½•"""
        # æ£€æŸ¥æ˜¯å¦æœ‰Pythonæ–‡ä»¶
        has_python_files = any(node_dir.glob('*.py'))

        # æ£€æŸ¥æ˜¯å¦è¢«ç¦ç”¨
        is_disabled = (
            (node_dir / '.disabled').exists() or
            node_dir.name.endswith('.disabled') or
            node_dir.name.startswith('disabled_')
        )

        return has_python_files and not is_disabled

    def _generate_scan_result(self, discovered_models: Dict[str, List[ModelInfo]],
                            match_results: Dict[str, MatchResult],
                            confidence_analysis: Dict[str, ConfidenceFactors],
                            github_analysis: Optional[Dict[str, GitHubRepoInfo]],
                            config: Dict[str, Any],
                            start_time: float) -> ScanResultV2:
        """ç”Ÿæˆæ‰«æç»“æœ"""

        # åˆå¹¶æ‰€æœ‰æ¨¡å‹
        all_models = []
        all_models.extend(discovered_models['single_file_models'])
        all_models.extend(discovered_models['directory_models'])

        # åˆ†ç±»æ¨¡å‹
        used_models = []
        unused_models = []
        uncertain_models = []

        confidence_threshold = config.get('confidence_threshold', 70)

        for model in all_models:
            model_id = f"{model.directory}/{model.name}"

            if model_id in confidence_analysis:
                # ä½¿ç”¨ç½®ä¿¡åº¦åˆ†æ•°ï¼Œéœ€è¦è½¬æ¢ä¸ºæœªä½¿ç”¨ç½®ä¿¡åº¦
                usage_confidence = confidence_analysis[model_id].total_score
                unused_confidence = 100 - usage_confidence  # è½¬æ¢ä¸ºæœªä½¿ç”¨ç½®ä¿¡åº¦

                # æ ¹æ®æœªä½¿ç”¨ç½®ä¿¡åº¦åˆ†ç±» - è°ƒæ•´é˜ˆå€¼ä½¿å…¶æ›´åˆç†
                if unused_confidence < 50:
                    # æœªä½¿ç”¨ç½®ä¿¡åº¦ < 50% = å¾ˆå¯èƒ½åœ¨ä½¿ç”¨
                    used_models.append(model)
                elif unused_confidence > confidence_threshold:
                    # æœªä½¿ç”¨ç½®ä¿¡åº¦ > é˜ˆå€¼ = å¾ˆå¯èƒ½æœªä½¿ç”¨
                    unused_models.append(model)
                else:
                    # 50% <= æœªä½¿ç”¨ç½®ä¿¡åº¦ <= é˜ˆå€¼ = ä¸ç¡®å®šçŠ¶æ€
                    uncertain_models.append(model)
            else:
                # æ²¡æœ‰ç½®ä¿¡åº¦åˆ†æçš„æ¨¡å‹è§†ä¸ºæœªä½¿ç”¨ï¼ˆæœªä½¿ç”¨ç½®ä¿¡åº¦100%ï¼‰
                unused_models.append(model)

        # è®¡ç®—å¤§å°ç»Ÿè®¡
        total_size = sum(model.size_bytes for model in all_models)
        used_size = sum(model.size_bytes for model in used_models)
        unused_size = sum(model.size_bytes for model in unused_models)

        scan_time = time.time() - start_time

        return ScanResultV2(
            # åŸºç¡€ç»Ÿè®¡
            total_models=len(all_models),
            single_file_models=len(discovered_models['single_file_models']),
            directory_models=len(discovered_models['directory_models']),

            # ä½¿ç”¨åˆ†æ
            used_models=used_models,
            unused_models=unused_models,
            uncertain_models=uncertain_models,

            # è¯¦ç»†åˆ†æ
            match_results=match_results,
            confidence_analysis=confidence_analysis,
            github_analysis=github_analysis,

            # ç»Ÿè®¡ä¿¡æ¯
            total_size_bytes=total_size,
            used_size_bytes=used_size,
            unused_size_bytes=unused_size,
            potential_savings_bytes=unused_size,

            # å…ƒæ•°æ®
            scan_time=f"{scan_time:.2f}ç§’",
            scan_timestamp=time.time(),
            scan_config=config.copy()
        )

    def _create_empty_scan_result(self, config: Dict[str, Any], scan_time: float) -> ScanResultV2:
        """åˆ›å»ºç©ºçš„æ‰«æç»“æœï¼ˆç”¨äºå–æ¶ˆæ—¶ï¼‰"""
        return ScanResultV2(
            # åŸºç¡€ç»Ÿè®¡
            total_models=0,
            single_file_models=0,
            directory_models=0,

            # ä½¿ç”¨åˆ†æ
            used_models=[],
            unused_models=[],
            uncertain_models=[],

            # è¯¦ç»†åˆ†æ
            match_results={},
            confidence_analysis={},
            github_analysis=None,

            # ç»Ÿè®¡ä¿¡æ¯
            total_size_bytes=0,
            used_size_bytes=0,
            unused_size_bytes=0,
            potential_savings_bytes=0,

            # å…ƒæ•°æ®
            scan_time=f"{scan_time:.2f}ç§’ (å·²å–æ¶ˆ)",
            scan_timestamp=time.time(),
            scan_config=config.copy()
        )
